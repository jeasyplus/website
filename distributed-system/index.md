# 分布式系统

分布式系统是相对于集中式应用而言，集中式是将系统所用的功能全部部署在一起。

集中式系统存在的问题：大而复杂、难于维护、容易发生单点故障、扩展性差。

分布式将系统拆分成多个应用，每个应用提供部分功能，整个分布式系统对外提供一整套服务。

## 分布式（distributed）：
在多台服务器中部署不同的服务，服务之间通过远程调用协同工作，并对外提供服务。

## 集群（cluster）：
在多台服务器中部署相同的应用，通过负载均衡设备对外提供服务。


## CAP理论
一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。

### 一致性（Consistency）

更新操作成功并给客户端返回完成后，所有节点的数据完全一致。

**客户端视角：** 多并发访问时更新过的数据如何获取的问题。

**服务端视角：** 更新如何复制分布到整个系统，以保证数据最终一致。

**一致性在并发读写的场景才有问题，因此，在理解一致性问题时，要注意结合并发读写的场景**。

### 一致性策略
**强一致性：** 更新的数据能被后续的访问都能看到。

**弱一致性：** 后续部分或者全部访问不到。

**最终一致性：** 经过一段时间后能访问到更新后的数据。

### 可用性（Availability）

服务一直可用，而且是正常响应时间。

对于分布式系统的可用性是指每一个非故障的节点必须对每一个请求作出响应，通常使用**停机时间**来衡量。

````
availability_data = [
{"容错可用性": "99.99%", "全年中的不可用时间": "少于 53 分钟"},
{"极高可用性": "99.999%", "全年中的不可用时间": "少于 5 分钟"},
{"具有故障自动恢复能力的可用性": "99.9999%", "全年中的不可用时间": "少于 1 分钟"},
{"高可用性": "99.9%", "全年中的不可用时间": "少于 8.8 小时"},
{"商品可用性": "99%", "全年中的不可用时间": "少于 3.65 天"}
]
````
**(1-0.99999)*365*24*60 = 5.256 min**

### 分区容错性（Partition Tolerance）

在分布式系统中**某节点或网络分区出现故障时**，仍然能够对外提供满足**一致性和可用性**的服务。

在网络中断、消息丢失的情况下，系统还能正常工作，就说明系统有比较好的分区容错性。

作为一个分布式系统，与单机系统的最大区别，就在于网络，要支持这种网络异常，相当于要满足分区容错性，能不能同时满足一致性和响应性呢？还是说要对他们进行取舍。


## CAP权衡

对于一致性、可用性和分区容错性要如何取舍？

### CA without P

在分布式系统中几乎是不存在的。

网络分区是一个客观事实，分区是必然的，如果舍弃P，意味着要舍弃分布式系统。

My Sql和Oracle是可用性和数据一致性有保障的，但它们不是分布式系统。

Google Spanner借助谷歌的广域网，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。

无法通过降低CA来提升P，提升系统分区容错性，需通过提升基础设施的稳定性来保障。

分布式系统P是一个基本要求，只能在CA之间做权衡，并想尽办法提升P。

### CP without A

容许系统停机或者长时间无响应，就说明在CAP中保障CP舍弃A。

发生网络故障或者消息丢失等情况时，就要牺牲用户的体验，等数据全部一致后让再允许用户访问系统。

分布式数据库都设计成CP，在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。

如：HBase、Zookeeper在CAP中选择优先保证CP。数据的一致性是它们的基本诉求。

Zookeeper使用ZAB（ZooKeeper Atomic Broadcast）协议实现一致性。
1、leader节点接收写消息将其转化成事务请求，为其分配一个全局唯一的递增事务ID。
2、Leader 节点将该事务请求广播给所有的 Follower 节点。
3、Follower 节点接收到 Leader 的广播消息后，将其应用到自己的数据副本上。
4、Follower 节点成功应用事务请求后，会向 Leader 节点发送确认消息。
5、Leader 节点将事务提交的通知发送给客户端，告知其事务已成功提交且已持久化。


### AP wihtout C

高可用并允许分区，则需放弃一致性。

发生网络问题节点之间失去联系，为保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，这样就会导致全局数据的不一致性。

舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。 对于很多业务系统来说，比如：淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。

主机众多、部署分散、集群规模大是目前分布式应用的特点，所以，节点故障、网络故障是常态，要保证服务可用性达到N个9，即保证P和A，舍弃C（只保证最终一致性）。虽影响用户体验，但造成用户流失的可能性较小。


## CAP理论

BASE理论是对CAP理论的延伸，核心思想是：**即使无法做到强一致性，但也可以采用适当的方式达到最终一致性（Eventual Consitency）**。

### 软状态（ Soft State）

允许系统存在中间状态，该中间状态不会影响系统整体可用性。分布式应用中数据至少会有三个副本，允许各副本同步的延时就是软状态的体现。mysql replication就是一种。


## 拜占庭将军问题

本质是分布式系统中的协同问题，即如何让分布式系统中的不同节点能在相互独立的情况下达成共识。

该问题对分布式系统的可靠性和安全性具有重要的意义，也是分布式系统研究中的一个重要话题。

解决该问题有许多方法：投票算法、共识算法。

这些算法的核心思想是：多数表决。

这个方案的前提假设是基于**叛徒数量**不超过**将军总数的一半**，否则无法保证多数投票结果是正确的。

解决方案对应的算法：Raft、ZAB、Paxos。

## 两阶段提交

二阶段提交(Two-phaseCommit)是XA分布式事务中一个重要方案。

核心思想：参与者将操作结果通知给协调者，由协调者根据所有参与者的反馈，决定各是否要提交操作。

### 第一阶段：准备阶段(投票阶段)。
**参与者1：** yes,i do

**参与者2：** yes,i do
### 第二阶段：提交阶段（执行阶段）。

**协调者**：Deal


2PC本身存在着同步阻塞、单点故障、数据不一致问题等。

## 三阶段提交

二阶段的基础上，增加了一个预提交阶段，组成3阶段提交方案。

3PC解决的问题就是协调者和参与者同时挂掉的问题，所以3PC把2PC的准备阶段一分为二。
### 准备阶段（CanCommit）
**参与者1**：Ready

**参与者2**：Ready

### 确认阶段（PreCommit）
**参与者1**：Commit Done

**参与者2**：Commit Done

### 完成阶段（DoCommit）

**协调者**：Deal

**总结：**

一台机器执行commit后挂掉，协调者从未挂掉的参与者中分析出来状态，并执行commit。
如果挂掉机的器之前执行的是rollback，协调者会对其他参与者执行rollback。

### 3PC的问题
在doCommit阶段，如果参与者无法及时收到协调者的doCommit或rebort请求，会在超时之后，继续进行事务提交。

由于网络原因，协调者发送的abort没有被参与者接收到，参与者在等待超时后执行了commit操作。

此时，与其他接到abort命令并执行回滚操作的参与者之间存在数据不一致的问题。

## 分布式锁

分布式锁有多种实现方式，常见的实现是基于数据库、Redis、Zookeeper。

## 分布式事务

涉及多个**独立操作节点**的事务，确保多节点操作的原子性、一致性、隔离性和持久性。

分布式事务常用的解决方案，如：XA协议、TCC事务、最大努力通知等。

都需要考虑如何**确保所有参与者的事务操作保持一致性**，以及如何**处理异常**情况。

## 分布式ID

数据库自增ID
号段模式：
很多分库分表的中间件的主键ID的生成，主要采用的也是号段模式，如：TDDL Sequence

基于Redis 实现
雪花算法

第三方工具：百度的UidGenerator、美团的Leaf、滴滴的Tinyid。


## TCC和2PC

TCC是Try-Confirm-Cancel的缩写，它是一种分布式事务解决方案，采用了基于业务逻辑的补偿机制，将整个分布式事务分解为若干个子事务，每个子事务都有一个try、confirm和cancel三个操作，通过这些操作来实现分布式事务的执行和回滚。

Try：try阶段执行成功，参与者返回一个成功标识，否则会返回失败标识。

Confirm：如果所有参与者的try阶段都执行成功，协调者通知所有参与者提交事务，进入confirm阶段，此时参与者在本地提交事务，并释放全局事务的资源。

Cancel：如果任何一个参与者在try阶段执行失败，协调者通知所有参与者回滚事务。进入cancel阶段，如果某个参与者在try阶段执行成功，在confirm阶段执行失败，则需要执行cancel操作，将之前预留的资源释放掉。

































